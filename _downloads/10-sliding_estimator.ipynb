{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\n# Sliding estimator\n\n\nA sliding estimator fits a logistic legression model for every time point.\nIn this example, we contrast the condition 'famous' against 'scrambled'\nusing this approach. The end result is an averaging effect across sensors.\nThe contrast across different sensors are combined into a single plot.\n\nResults script: `sphx_glr_auto_examples_statistics_plot_sliding_estimator.py`\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "Let us first import the libraries\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "import os\n\nimport numpy as np\nfrom scipy.io import savemat\n\nimport mne\nfrom mne.decoding import SlidingEstimator, cross_val_multiscore\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LogisticRegression\n\nfrom library.config import meg_dir, l_freq, N_JOBS, random_state"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Then we write a function to do time decoding on one subject\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "def run_time_decoding(subject_id, condition1, condition2):\n    print(\"processing subject: %s (%s vs %s)\"\n          % (subject_id, condition1, condition2))\n\n    subject = \"sub%03d\" % subject_id\n    data_path = os.path.join(meg_dir, subject)\n    epochs = mne.read_epochs(os.path.join(data_path,\n                             '%s_highpass-%sHz-epo.fif' % (subject, l_freq)))\n\n    # We define the epochs and the labels\n    epochs = mne.concatenate_epochs([epochs[condition1],\n                                    epochs[condition2]])\n    epochs.apply_baseline()\n\n    # Let us restrict ourselves to the MEG channels, and also decimate to\n    # make it faster (although we might miss some detail / alias)\n    epochs.pick_types(meg=True).decimate(4, verbose='error')\n\n    # Get the data and labels\n    X = epochs.get_data()\n    n_cond1 = len(epochs[condition1])\n    n_cond2 = len(epochs[condition2])\n    y = np.r_[np.ones(n_cond1), np.zeros(n_cond2)]\n\n    # Use AUC because chance level is same regardless of the class balance\n    se = SlidingEstimator(\n        make_pipeline(StandardScaler(),\n                      LogisticRegression(random_state=random_state)),\n        scoring='roc_auc', n_jobs=N_JOBS)\n    cv = StratifiedKFold(random_state=random_state)\n    scores = cross_val_multiscore(se, X=X, y=y, cv=cv)\n\n    # let's save the scores now\n    a_vs_b = '%s_vs_%s' % (os.path.basename(condition1),\n                           os.path.basename(condition2))\n    fname_td = os.path.join(data_path, '%s_highpass-%sHz-td-auc-%s.mat'\n                            % (subject, l_freq, a_vs_b))\n    savemat(fname_td, {'scores': scores, 'times': epochs.times})\n\n\n# Here we go parallel inside the :class:`mne.decoding.SlidingEstimator`\n# so we don't dispatch manually to multiple jobs.\n\nfor subject_id in range(1, 20):\n    for conditions in (('face', 'scrambled'),\n                       ('face/famous', 'face/unfamiliar')):\n        run_time_decoding(subject_id, *conditions)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.12", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n===============================\nDecoding (ML) across time (MEG)\n===============================\n\nA sliding estimator fits a logistic regression model for every time point.\nIn this example, we contrast the condition `'famous'` vs `'scrambled'`\nand `'famous'` vs `'unfamiliar'` using this approach. The end result is an\naveraging effect across sensors. The contrast across different sensors are\ncombined into a single plot.\n\nAnalysis script: `sphx_glr_auto_scripts_10-sliding_estimator.py`\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us first import the necessary libraries\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport os.path as op\nimport sys\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.io import loadmat\nfrom scipy.stats import sem\n\nsys.path.append(op.join('..', '..', 'processing'))\nfrom library.config import (meg_dir, l_freq, annot_kwargs, tmax,\n                            set_matplotlib_defaults)  # noqa: E402"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we loop over subjects to load the scores\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "a_vs_bs = ['face_vs_scrambled', 'famous_vs_unfamiliar']\nscores = {'face_vs_scrambled': list(), 'famous_vs_unfamiliar': list()}\nfor subject_id in range(1, 20):\n    subject = \"sub%03d\" % subject_id\n    data_path = os.path.join(meg_dir, subject)\n\n    # Load the scores for the subject\n    for a_vs_b in a_vs_bs:\n        fname_td = os.path.join(data_path, '%s_highpass-%sHz-td-auc-%s.mat'\n                                % (subject, l_freq, a_vs_b))\n        mat = loadmat(fname_td)\n        scores[a_vs_b].append(mat['scores'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "... and average them\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "times = mat['times'][0]\nmean_scores, sem_scores = dict(), dict()\nfor a_vs_b in a_vs_bs:\n    mean_scores[a_vs_b] = np.mean(scores[a_vs_b], axis=0)\n    sem_scores[a_vs_b] = sem(scores[a_vs_b])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the mean AUC score across subjects\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "set_matplotlib_defaults()\ncolors = ['b', 'g']\nfig, ax = plt.subplots(1, figsize=(3.3, 2.5))\nfor c, a_vs_b in zip(colors, a_vs_bs):\n    ax.plot(times, mean_scores[a_vs_b], c, label=a_vs_b.replace('_', ' '))\n    ax.set(xlabel='Time (s)', ylabel='Area under curve (AUC)')\n    ax.fill_between(times, mean_scores[a_vs_b] - sem_scores[a_vs_b],\n                    mean_scores[a_vs_b] + sem_scores[a_vs_b],\n                    color=c, alpha=0.33, edgecolor='none')\nax.axhline(0.5, color='k', linestyle='--', label='Chance level')\nax.axvline(0.0, color='k', linestyle='--')\nax.legend()\nax.set(xlim=[-0.2, tmax])\nax.annotate('B', (-0.15, 1), **annot_kwargs)\nfig.tight_layout(pad=0.5)\nfig.savefig(op.join('..', 'figures', 'time_decoding_highpass-%sHz.pdf'\n                    % (l_freq,)), bbox_to_inches='tight')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It seems that `'famous'` vs `'unfamiliar'` gives much noisier time course of\ndecoding scores than `'faces'` vs `'scrambled'`. To verify that this is not\ndue to bad subjects:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(4, 5, sharex=True, sharey=True,\n                         figsize=(7, 7))\naxes = axes.ravel()\nfor idx in range(19):\n    axes[idx].axhline(0.5, color='k', linestyle='--', label='Chance level')\n    axes[idx].axvline(0.0, color='k', linestyle='--')\n    for a_vs_b in a_vs_bs:\n        axes[idx].plot(times, scores[a_vs_b][idx], label=a_vs_b)\n        axes[idx].set_title('sub%03d' % (idx + 1))\n\naxes[-1].axis('off')\naxes[-2].legend(bbox_to_anchor=(2.2, 0.75), loc='center right')\nfig.text(0.5, 0.02, 'Time (s)', ha='center', fontsize=16)\nfig.text(0.01, 0.5, 'Area under curve (AUC)', va='center',\n         rotation='vertical', fontsize=16)\nfig.subplots_adjust(bottom=0.1, left=0.1, right=0.98, top=0.95)\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}